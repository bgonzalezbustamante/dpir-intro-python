{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `pandas` part 1\n",
    "\n",
    "This week we learn about the following five areas of pandas:\n",
    "\n",
    "- Data I/O\n",
    "- Understanding the `DataFrame` and `Series`\n",
    "- Indexing and Filtering\n",
    "- Renaming and Replacing\n",
    "- First look at the data\n",
    "- Summary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Importing Libraries\n",
    "\n",
    "In python, we use the `import` statement to \"load\" code from other libraries. This is similar to the `library()` function in `R`.\n",
    "\n",
    "Note we can also use `import library as lib` to rename the imported library. Although it makes for less typing, I recommend sticking to widely accepted abbreviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.__version__ # you can check the version of any library with this command\n",
    "               # if you get anything older than 0.25.0, try updating pandas with: conda update pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Creating the `DataFrame` and `Series`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `pd.Series`\n",
    "\n",
    "The pandas `Series` is a one-dimensional ordered and labelled data container.\n",
    "\n",
    "To pull up the associated documentation on a class, method or module, use the `?` magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can create a series by calling the `pd.Series()` function on a one-dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ser = pd.Series([1, 4, 7, -1, 12])\n",
    "ser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note that the default behaviour is to use an integer index ranging from 0 to the length of the input minus 1.\n",
    "\n",
    "We can override this behaviour by passing an equal length array as an index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ser = pd.Series([1, 4, 7, -1, 12], index = ['a', 'b', 'd', 'z', 'dinosaur'])\n",
    "ser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `pd.DataFrame`\n",
    "\n",
    "The `pandas.DataFrame` is a two-dimensional tabular data container. You can think of each column of the dataframe as being a series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Dataframes can be constructed in a multitude of ways. I prefer using a combination of dicts and lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Create the data as a dict of lists:\n",
    "my_data = {\n",
    "    'col1': [1, 4, 7, 10],\n",
    "    'col2': [1/1, 1/4, 1/7, 1/10],\n",
    "    'col3': ['tea', 'coffee', 'toffee', 'key']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Optional: Create the column list if necessary (dict keys are unordered!)\n",
    "my_columns = ['col1', 'col2', 'col3']\n",
    "\n",
    "# Index is also optional\n",
    "my_index = ['a', 'b', 'c', 'pterodactyl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=my_data, columns=my_columns, index=my_index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# We can also do this without the intermediary steps\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data = {\n",
    "        'col1': [1, 4, 7, 10],\n",
    "        'col2': [1/1, 1/4, 1/7, 1/10],\n",
    "        'col3': ['tea', 'coffee', 'toffee', 'key']\n",
    "    },\n",
    "    columns = ['col1', 'col2', 'col3'],\n",
    "    index = ['a', 'b', 'c', 'pterodactyl']\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reading in Data\n",
    "\n",
    "For this lecture we use the BES data. The data can be downloaded from: https://github.com/muhark/dpir-intro-python/raw/master/Week2/bes_data_subset_week2.feather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The original file was in `dta` format, but I've saved it in a number of formats.\n",
    "Here are the file names with their associated sizes in kilobytes.\n",
    "\n",
    "```\n",
    "360K    bes_data_subset_week2.csv\n",
    "296K    bes_data_subset_week2.feather\n",
    "636K    bes_data_subset_week2.json\n",
    "```\n",
    "\n",
    "Let's just use the `feather` format for now, as this is the easiest to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "bes_df = pd.read_feather(\"bes_data_subset_week2.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can view the first/last 30 rows (and 20 columns) by just writing the name of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To get the names of the indices or columns, you can use the `.index` or `.columns` methods of a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bes_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bes_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Indexing Data in `Series` and `DataFrame`\n",
    "\n",
    "Indexing refers to selecting one or more elements within a data structure. This is the most basic and useful functionality of a data container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Indexing `pd.Series`\n",
    "\n",
    "We can _view_ elements of a pandas series in a similar method to either a dict or a list using the `[]`.\n",
    "\n",
    "Note that if we pass an integer, it will index like a list, whereas if we pass a key (i.e. a string), it will index like a dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(ser[0])\n",
    "print(ser['a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Indexing `pd.DataFrame`\n",
    "\n",
    "The DataFrame understands the `[]` accessor as if it were a dictionary.\n",
    "\n",
    "Passing a scalar value to the `[]` accessor returns a _view_ of a `Series`; passing a list returns a _view_ of a `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "bes_df['region'] # Single input: name of column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "bes_df[['a01', 'region']] # Multiple input: list of column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## General Indexing: `loc`, `iloc`\n",
    "\n",
    "You can always use the  `loc` and `iloc` methods for indexing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `pd.DataFrame.loc[]`\n",
    "\n",
    "The `pd.DataFrame.loc[ , ]` function takes two arguments inside the `[ , ]`: _row(s)_ and _column(s)_\n",
    "\n",
    "When using `loc`, you must use the column and index _names_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.loc['a', 'col3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[['a', 'pterodactyl'], ['col1', 'col2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `pd.DataFrame.iloc[]`\n",
    "\n",
    "`pd.DataFrame.iloc[ , ]` is similar to `loc`, but uses _locational_ instead of _named_ indexing.\n",
    "\n",
    "This means you should pass the location of elements by their implicit numeric index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[[0, -1], [0, 1]] # Remember -1 is the location of the last element of an array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Filtering Data on Rows\n",
    "\n",
    "Filtering is similar to indexing, but uses logical conditions to choose a subset of elements.\n",
    "\n",
    "There are a multitude of methods for doing this; I go over the one I use most frequently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Say I want to filter BES data for respondents in Scotland.\n",
    "\n",
    "By using a logical condition, `==` with a Series, I get a Series of Booleans indicating whether the condition is True/False for each element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bes_df['region']=='Scotland'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Remember, I can use the sum function with Booleans to get the number of Trues.\n",
    "sum(bes_df['region']=='Scotland')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can pass this to the the indexer to get a subset of the `DataFrame` or `Series`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bes_df.loc[bes_df['region']=='Scotland', :] # \":\" indicates \"all values\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering on multiple values is similar. Use multiple conditions joined by a binary logical operator.\n",
    "\n",
    "Remember to use parentheses to ensure that the items are evaluated in the correct order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = (bes_df['region']=='Scotland') & (bes_df['Constit_Code']=='Angus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bes_df[cond] # We can use this here; see further on in the lecture for when this is acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renaming and replacing\n",
    "\n",
    "- Renaming: renaming columns or indices\n",
    "- Replacing: replacing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming columns or indices\n",
    "\n",
    "We can rename columns and indices using the `pd.DataFrame.rename()` function and a dictionary.\n",
    "\n",
    "Note that you should specify the _axis_. `axis=0` is rows, `axis=1` is columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename({'pterodactyl':'d'}, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `df` will not be altered unless you assign the output of the function to a variable. To overwrite in place, assign the output of the function to itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename({'pterodactyl':'d'}, axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming columns is similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename({'col1': 'num1', 'col2': 'num2', 'col3': 'str1'}, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on use of capital letters and underscores\n",
    "\n",
    "Keep in mind that you will be writing the column names a lot. Do your best to keep column names short, meaningful, and stick to a consistent pattern of uppercase and underscores.\n",
    "\n",
    "I use `snake_case` for column names, which means all lowercase with underscores between words. An alternative is `CamelCase`, which uses no underscores but capitalises the first letter of each word.\n",
    "\n",
    "Standard python practice is to use `snake_case` for variables, functions, and modules, but `CamelCase` for classes. Hence, `pandas.DataFrame`, but `pandas.Dataframe.value_counts()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reindexing\n",
    "\n",
    "Re-indexing can be done with the `.set_index()` or `.reset_index()` methods.\n",
    "\n",
    "When resetting, if you do not pass `drop=True`, then the existing index will be added to the dataframe as a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('str1', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing values\n",
    "\n",
    "We can use the `pd.Series.replace` or `pd.DataFrame.replace` function to replace values within the series or dataframe. This is also straightforward with a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bes_df['a02'].replace({'Conservatives': 'Tories'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warning: `loc` vs `[]`\n",
    "\n",
    "Here's a tedious and tricky thing:\n",
    "\n",
    "- `df[col_name]` returns a _view_ of the dataframe.\n",
    "- `df.loc[:, col_name]` returns the _contents_ of the dataframe.\n",
    "\n",
    "Assigning values to a view (with `=`) is ambiguous. Python does not know whether to alter the object, or the view of that object that was created in that instance.\n",
    "\n",
    "Therefore whenever writing values into some subset of a pandas object, use the `loc` or `iloc` accessors, so that python understands that you want to modify the underlying object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not do this\n",
    "df['num1'] = [0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this\n",
    "df.loc[:, 'num1'] = [1, 4, 7, 10]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First-Look Functions\n",
    "\n",
    "When working with data, your first step should always be _getting to know the data_. Ask questions like:\n",
    "\n",
    "- What does the top/bottom of the dataset look like? `df.head()`, `df.tail()`\n",
    "- What are the dimensions of the dataset? `df.shape`\n",
    "- What are my columns and rows? `df.columns`, `df.index`\n",
    "- What data types are each of the columns? Is this expected? `df.info()`, `df.dtypes`\n",
    "- How sparse is my data? (Looking for NAs) `df.info()`, `df.isna().sum()`\n",
    "- What unique values does each column contain? `series.unique()`, `series.value_counts()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Head/Tail\n",
    "\n",
    "The `df.head()` and `df.tail()` functions return the first/last 5 rows of the dataframe by default. The number of rows can be passed to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bes_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensions\n",
    "\n",
    "It's good to know how many entries are in your dataset.\n",
    "\n",
    "`df.shape` (not a function!) returns a tuple; the first value is the number of rows (observations), the second is the number of columns (variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2194, 15)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bes_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns and Rows\n",
    "\n",
    "The `df.columns` and `df.index` methods return the columns and rows respectively.\n",
    "\n",
    "Both of these are `pd.Index` objects; to change them into base python lists you can use the `.tolist()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['finalserialno', 'a01', 'a02', 'a03', 'region', 'recontact', 'agency', 'Constit_Code', 'Constit_Name', 'Interview_Date', 'total_num_dwel', 'total_num_hous', 'num_elig_people', 'edlevel', 'turnoutValidationReg']\n",
      "RangeIndex(start=0, stop=2194, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(bes_df.columns.tolist())\n",
    "print(bes_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data types and NAs\n",
    "\n",
    "Pandas series can only contain one data type; therefore each column in your data will have a single type.\n",
    "\n",
    "Pandas does not use base python data types. For an overview of the pandas data types, see [this blog post](https://pbpython.com/pandas_dtypes.html).\n",
    "\n",
    "We can view these with either `df.dtypes` or `df.info()`.\n",
    "\n",
    "The latter also contains information about the number of non-null (i.e. not NA) values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2194 entries, 0 to 2193\n",
      "Data columns (total 15 columns):\n",
      "finalserialno           2194 non-null int32\n",
      "a01                     2194 non-null object\n",
      "a02                     2132 non-null category\n",
      "a03                     2194 non-null category\n",
      "region                  2194 non-null object\n",
      "recontact               2194 non-null category\n",
      "agency                  2194 non-null category\n",
      "Constit_Code            2194 non-null object\n",
      "Constit_Name            2194 non-null object\n",
      "Interview_Date          2194 non-null object\n",
      "total_num_dwel          2194 non-null object\n",
      "total_num_hous          2194 non-null object\n",
      "num_elig_people         2194 non-null object\n",
      "edlevel                 2156 non-null category\n",
      "turnoutValidationReg    1507 non-null category\n",
      "dtypes: category(6), int32(1), object(8)\n",
      "memory usage: 159.9+ KB\n"
     ]
    }
   ],
   "source": [
    "bes_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Values\n",
    "\n",
    "It's also important to know the possible values that a column can contain.\n",
    "\n",
    "We can see the unique values with the `df[col_name].unique()` function.\n",
    "\n",
    "We can tabulate these values with the `df[col_name].value_counts()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Labour, None/No party, Don`t know, Conservatives, Liberal Democrats, ..., NaN, Green Party, All of them/ more than one, Refused, Plaid Cymru]\n",
       "Length: 13\n",
       "Categories (12, object): [Refused < Don`t know < None/No party < Labour ... Green Party < United Kingdom Independence Party (UKIP) < Other < All of them/ more than one]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bes_df['a02'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "North West            304\n",
       "South East            282\n",
       "West Midlands         227\n",
       "Eastern               226\n",
       "London                212\n",
       "Scotland              191\n",
       "Yorkshire & Humber    187\n",
       "South West            167\n",
       "East Midlands         156\n",
       "Wales                 129\n",
       "North East            113\n",
       "Name: region, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bes_df['region'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Functions\n",
    "\n",
    "One of the greatest advantages of pandas objects are the range of built-in statistical summaries.\n",
    "\n",
    "These include:\n",
    "\n",
    "- `.sum()`\n",
    "- `.mean()`\n",
    "- `.var()`\n",
    "- `.std()`\n",
    "- `.mode()`\n",
    "\n",
    "For a full reference, see: https://pandas.pydata.org/pandas-docs/version/0.25/getting_started/basics.html?highlight=variance#descriptive-statistics\n",
    "\n",
    "\n",
    "Dataframe summaries usually require an axis to be specified (rows: default, `axis=0`, columns: `axis=1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num1                    22\n",
       "num2               1.49286\n",
       "str1    teacoffeetoffeekey\n",
       "dtype: object"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1.000000\n",
       "b    2.125000\n",
       "c    3.571429\n",
       "d    5.050000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['num1', 'num2']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a01</th>\n",
       "      <th>a02</th>\n",
       "      <th>a03</th>\n",
       "      <th>region</th>\n",
       "      <th>recontact</th>\n",
       "      <th>agency</th>\n",
       "      <th>Constit_Code</th>\n",
       "      <th>Constit_Name</th>\n",
       "      <th>Interview_Date</th>\n",
       "      <th>total_num_dwel</th>\n",
       "      <th>total_num_hous</th>\n",
       "      <th>num_elig_people</th>\n",
       "      <th>edlevel</th>\n",
       "      <th>turnoutValidationReg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>brexit</td>\n",
       "      <td>Conservatives</td>\n",
       "      <td>Fairly interested</td>\n",
       "      <td>North West</td>\n",
       "      <td>No</td>\n",
       "      <td>Kantar</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>S14000028</td>\n",
       "      <td>14/07/2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Voted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      a01            a02                a03      region recontact  agency  \\\n",
       "0  brexit  Conservatives  Fairly interested  North West        No  Kantar   \n",
       "\n",
       "  Constit_Code Constit_Name Interview_Date total_num_dwel total_num_hous  \\\n",
       "0   Birmingham    S14000028     14/07/2017              1              1   \n",
       "\n",
       "  num_elig_people        edlevel turnoutValidationReg  \n",
       "0               2  Undergraduate                Voted  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bes_df.iloc[:, 1:].mode(axis=0) # Excludes first column"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "teaching",
   "language": "python",
   "name": "teaching"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
