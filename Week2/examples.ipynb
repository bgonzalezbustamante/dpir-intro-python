{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `pandas` part 1\n",
    "\n",
    "This week we learn about the following five areas of pandas:\n",
    "\n",
    "- Data I/O\n",
    "- Understanding the `DataFrame` and `Series`\n",
    "- Indexing and Filtering\n",
    "- Renaming \n",
    "and Replacing\n",
    "- First look at the data\n",
    "- Summary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Importing Libraries\n",
    "\n",
    "In python, we use the `import` statement to \"load\" code from other libraries. This is similar to the `library()` function in `R`.\n",
    "\n",
    "Note we can also use `import` _library name_ `as` _abbreviation_ to rename the imported library. Although it makes for less typing, I recommend sticking to widely accepted abbreviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.__version__ # you can check the version of any library with this command\n",
    "               # if you get anything older than 0.25.0, try updating pandas with: conda update pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `DataFrame` and `Series`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `pd.Series`\n",
    "\n",
    "The pandas `Series` is a one-dimensional ordered and labelled data container.\n",
    "\n",
    "To pull up the associated documentation on a class, method or module, use the `?` magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can create a series by calling the `pd.Series()` function on a one-dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ser = pd.Series([1, 4, 7, -1, 12])\n",
    "ser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note that the default behaviour is to use an integer index ranging from 0 to the length of the input minus 1.\n",
    "\n",
    "We can override this behaviour by passing an equal length array as an index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ser = pd.Series([1, 4, 7, -1, 12], index = ['a', 'b', 'd', 'z', 'dinosaur'])\n",
    "ser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `pd.DataFrame`\n",
    "\n",
    "The `pandas.DataFrame` is a two-dimensional tabular data container. You can think of each column of the dataframe as being a series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Dataframes can be constructed in a multitude of ways. I prefer using a combination of dicts and lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Create the data as a dict of lists:\n",
    "my_data = {\n",
    "    'col1': [1, 4, 7, 10],\n",
    "    'col2': [1/1, 1/4, 1/7, 1/10],\n",
    "    'col3': ['tea', 'coffee', 'toffee', 'key']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Optional: Create the column list if necessary (dict keys are unordered!)\n",
    "my_columns = ['col1', 'col2', 'col3']\n",
    "\n",
    "# Index is also optional\n",
    "my_index = ['a', 'b', 'c', 'pterodactyl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=my_data, columns=my_columns, index=my_index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# We can also do this without the intermediary steps\n",
    "df = pd.DataFrame(\n",
    "    data = {\n",
    "        'col1': [1, 4, 7, 10],\n",
    "        'col2': [1/1, 1/4, 1/7, 1/10],\n",
    "        'col3': ['tea', 'coffee', 'toffee', 'key']\n",
    "    },\n",
    "    columns = ['col1', 'col2', 'col3'],\n",
    "    index = ['a', 'b', 'c', 'pterodactyl']\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reading in Data\n",
    "\n",
    "For this lecture we use the BES data. The data can be downloaded from: https://muhark.github.io/dpir-intro-python/Week2/data/data_week2.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The original file was in `dta` format, but I've saved it in a number of formats.\n",
    "Here are the file names with their associated sizes in kilobytes.\n",
    "\n",
    "```\n",
    "756K    bes_data_subset_week2.csv\n",
    "348K    bes_data_subset_week2.feather\n",
    "1.3M    bes_data_subset_week2.json\n",
    "```\n",
    "\n",
    "Let's just use the `feather` format for now, as this is the easiest to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "bes_df = pd.read_feather(\"data/bes_data_subset_week2.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can view the first/last 30 rows (and 20 columns) by just writing the name of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To get the names of the indices or columns, you can use the `.index` or `.columns` methods of a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bes_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "bes_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Indexing Data in `Series` and `DataFrame`\n",
    "\n",
    "Indexing refers to selecting one or more elements within a data structure. This is the most basic and useful functionality of a data container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Indexing `pd.Series`\n",
    "\n",
    "We can _view_ elements of a pandas series in a similar method to either a dict or a list using the `[]`.\n",
    "\n",
    "Note that if we pass an integer, it will index like a list, whereas if we pass a key (i.e. a string), it will index like a dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(ser[0])\n",
    "print(ser['a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Indexing `pd.DataFrame`\n",
    "\n",
    "The DataFrame understands the `[]` accessor as if it were a dictionary.\n",
    "\n",
    "Passing a scalar value to the `[]` accessor returns a _view_ of a `Series`; passing a list returns a _view_ of a `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "bes_df['region'] # Single input: name of column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "bes_df[['a01', 'region']] # Multiple input: list of column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## General Indexing: `loc`, `iloc`\n",
    "\n",
    "You can always use the  `loc` and `iloc` methods for indexing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `pd.DataFrame.loc[]`\n",
    "\n",
    "The `pd.DataFrame.loc[ , ]` function takes two arguments inside the `[ , ]`: _row(s)_ and _column(s)_\n",
    "\n",
    "When using `loc`, you must use the column and index _names_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.loc['a', 'col3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[['a', 'pterodactyl'], ['col1', 'col2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `pd.DataFrame.iloc[]`\n",
    "\n",
    "`pd.DataFrame.iloc[ , ]` is similar to `loc`, but uses _locational_ instead of _named_ indexing.\n",
    "\n",
    "This means you should pass the location of elements by their implicit numeric index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[[0, -1], [0, 1]] # Remember -1 is the location of the last element of an array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Filtering Data on Rows\n",
    "\n",
    "Filtering is similar to indexing, but uses logical conditions to choose a subset of elements.\n",
    "\n",
    "There are a multitude of methods for doing this; I go over the one I use most frequently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Say I want to filter BES data for respondents in Scotland.\n",
    "\n",
    "By using a logical condition, `==` with a Series, I get a Series of Booleans indicating whether the condition is True/False for each element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bes_df['region']=='Scotland'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Remember, we can use the sum function with Booleans to get the number of Trues.\n",
    "sum(bes_df['region']=='Scotland')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can pass this to the the indexer to get a subset of the `DataFrame` or `Series`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bes_df.loc[bes_df['region']=='Scotland', :] # \":\" indicates \"all values\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Filtering on multiple values is similar. Use multiple conditions joined by a binary logical operator (and: `&`, or: `|`)\n",
    "\n",
    "Remember to use parentheses to ensure that the items are evaluated in the correct order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "cond = (bes_df['region']=='Scotland') & (bes_df['Constit_Code']=='Angus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bes_df[cond] # We can use this here; see further on in the lecture for when this is acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Renaming and replacing\n",
    "\n",
    "- Renaming: renaming columns or indices\n",
    "- Replacing: replacing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Renaming columns or indices\n",
    "\n",
    "We can rename columns and indices using the `pd.DataFrame.rename()` function and a dictionary.\n",
    "\n",
    "Note that you should specify the _axis_. `axis=0` is rows, `axis=1` is columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.rename({'pterodactyl':'d'}, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note that `df` will not be altered unless you assign the output of the function to a variable. To overwrite in place, assign the output of the function to itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = df.rename({'pterodactyl':'d'}, axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Renaming columns is similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = df.rename({'col1': 'num1', 'col2': 'num2', 'col3': 'str1'}, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Note on use of capital letters and underscores\n",
    "\n",
    "Keep in mind that you will be writing the column names a lot. Do your best to keep column names short, meaningful, and stick to a consistent pattern of uppercase and underscores.\n",
    "\n",
    "I use `snake_case` for column names, which means all lowercase with underscores between words. An alternative is `CamelCase`, which uses no underscores but capitalises the first letter of each word.\n",
    "\n",
    "Standard python practice is to use `snake_case` for variables, functions, and modules, but `CamelCase` for classes. Hence, `pandas.DataFrame`, but `pandas.Dataframe.value_counts()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Reindexing\n",
    "\n",
    "Re-indexing can be done with the `.set_index()` or `.reset_index()` methods.\n",
    "\n",
    "When resetting, if you do not pass `drop=True`, then the existing index will be added to the dataframe as a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.set_index('str1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Replacing values\n",
    "\n",
    "We can use the `pd.Series.replace` or `pd.DataFrame.replace` function to replace values within the series or dataframe. This is also straightforward with a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bes_df['a02'].replace({'Don`t know': 'idk'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Warning: `loc` vs `[]`\n",
    "\n",
    "Here's a tedious and tricky thing:\n",
    "\n",
    "- `df[col_name]` returns a _view_ of the dataframe.\n",
    "- `df.loc[:, col_name]` returns the _contents_ of the dataframe.\n",
    "\n",
    "Assigning values to a view (with `=`) is ambiguous. Python does not know whether to alter the object, or the view of that object that was created in that moment.\n",
    "\n",
    "Therefore whenever writing values into some subset of a pandas object, use the `loc` or `iloc` accessors, so that python understands that you want to modify the underlying object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Do not do this\n",
    "df['num1'] = [0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Do this\n",
    "df.loc[:, 'num1'] = [0, 0, 7, 10]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# First-Look Functions\n",
    "\n",
    "When working with data, your first step should always be _getting to know the data_. Ask questions like:\n",
    "\n",
    "- What does the top/bottom of the dataset look like? `df.head()`, `df.tail()`\n",
    "- What are the dimensions of the dataset? `df.shape`\n",
    "- What are my columns and rows? `df.columns`, `df.index`\n",
    "- What data types are each of the columns? Is this expected? `df.info()`, `df.dtypes`\n",
    "- How sparse is my data? (Looking for NAs) `df.info()`, `df.isna().sum()`\n",
    "- What unique values does each column contain? `series.unique()`, `series.value_counts()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Head/Tail\n",
    "\n",
    "The `df.head()` and `df.tail()` functions return the first/last 5 rows of the dataframe by default. The number of rows can be passed to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "bes_df.iloc[:, :10].head() # Using iloc to make output easier to read in lecture slide; not necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "bes_df.iloc[:, 3:10].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dimensions\n",
    "\n",
    "It's good to know how many entries are in your dataset.\n",
    "\n",
    "`df.shape` (not a function!) returns a tuple; the first value is the number of rows (observations), the second is the number of columns (variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bes_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Columns and Rows\n",
    "\n",
    "The `df.columns` and `df.index` methods return the columns and rows respectively.\n",
    "\n",
    "Both of these are `pd.Index` objects; to change them into base python lists you can use the `.tolist()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(bes_df.columns.tolist())\n",
    "print(bes_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data types and NAs\n",
    "\n",
    "Pandas series can only contain one data type; therefore each column in your data will have a single type.\n",
    "\n",
    "Pandas does not use base python data types. For an overview of the pandas data types, see [this blog post](https://pbpython.com/pandas_dtypes.html).\n",
    "\n",
    "We can view these with either `df.dtypes` or `df.info()`.\n",
    "\n",
    "The latter also contains information about the number of non-null (i.e. not NA) values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "bes_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Unique Values\n",
    "\n",
    "It's also important to know the possible values that a column can contain.\n",
    "\n",
    "We can see the unique values with the `df[col_name].unique()` function.\n",
    "\n",
    "We can tabulate these values with the `df[col_name].value_counts()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "bes_df['a02'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "bes_df['region'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary Functions\n",
    "\n",
    "One of the greatest advantages of pandas objects are the range of built-in statistical summaries.\n",
    "\n",
    "These include:\n",
    "\n",
    "- `.sum()`\n",
    "- `.mean()`\n",
    "- `.var()`\n",
    "- `.std()`\n",
    "- `.mode()`\n",
    "\n",
    "For a full reference, see: https://pandas.pydata.org/pandas-docs/version/0.25/getting_started/basics.html?highlight=variance#descriptive-statistics\n",
    "\n",
    "\n",
    "Dataframe summaries usually require an axis to be specified (rows: default, `axis=0`, columns: `axis=1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df[['num1', 'num2']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "bes_df.iloc[:, 1:].mode(axis=0) # Excludes first column"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "teaching",
   "language": "python",
   "name": "teaching"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
